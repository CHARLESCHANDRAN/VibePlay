# VibePlay ‚Äî React Native CLI Starter (JavaScript)

Integrated: Google Cloud Vision API for emotion detection

A React Native mood-based recommendation app that suggests movies and music based on detected emotions. Tech-Slick AI ‚Ä¢ Camera + Manual Mood ‚Ä¢ Movies (TMDb) + Music (Spotify via proxy)

## üìÅ Project Structure## What This Is

A **JavaScript** starter to overlay onto a fresh **React Native CLI** app. It includes:

`````- Navigation + dark neon theme

VibePlay/- Screens: Onboarding, CaptureMood, Intent, Recommendations, Saved

‚îú‚îÄ‚îÄ src/- Zustand store for mood/intent/energy/valence

‚îÇ   ‚îú‚îÄ‚îÄ components/          # Reusable UI components- TMDb integration + Spotify proxy stub

‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ CameraCapture.js- **Stubbed emotion detector** (simulated) ‚Äî swap in VisionCamera + model later

‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ErrorBoundary.js- `.env.example` for keys

‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ MoodSelector.js

‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ NeonButton.js---

‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ RecommendationCard.js

‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SkeletonLoaders.js## 1) Create a fresh RN CLI app

‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Toast.js

‚îÇ   ‚îú‚îÄ‚îÄ screens/             # Screen-level components```bash

‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ CaptureMood.jsnpx react-native init VibePlay --version 0.76.0

‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Intent.jscd VibePlay

‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Onboarding.js```

‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Recommendations.js

‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Saved.js## 2) Copy the template files over

‚îÇ   ‚îú‚îÄ‚îÄ navigation/          # Navigation configurationCopy the contents of this zip into your project root, **merging** folders:

‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ AppNavigator.js- `App.js`

‚îÇ   ‚îú‚îÄ‚îÄ hooks/               # Custom React hooks- `src/*`

‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ useEmotionDetector.js- `.env.example`

‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ useToast.js- `package.json` (merge dependencies into your app's package.json if needed)

‚îÇ   ‚îú‚îÄ‚îÄ services/            # API and external services- `babel.config.js` (ensures Reanimated plugin)

‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mapMood.js

‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ spotify.jsInstall deps:

‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tmdb.js

‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ visionApi.js```bash

‚îÇ   ‚îú‚îÄ‚îÄ config/              # App configurationnpm i @react-navigation/native @react-navigation/native-stack react-native-gesture-handler react-native-reanimated react-native-screens react-native-safe-area-context react-native-svg react-native-config zustand react-native-vision-camera

‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ index.js         # Environment variables```

‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ build.config.json # Build configuration

‚îÇ   ‚îú‚îÄ‚îÄ state/               # State management (Zustand)iOS pods:

‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ store.js

‚îÇ   ‚îú‚îÄ‚îÄ theme/               # Theme and styling```bash

‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ colors.jscd ios && pod install && cd ..

‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ styles.js```

‚îÇ   ‚îú‚îÄ‚îÄ utils/               # Utility functions

‚îÇ   ‚îî‚îÄ‚îÄ assets/              # Images, fonts, etc.## 3) Environment variables

‚îú‚îÄ‚îÄ ios/                     # Native iOS projectCreate `.env` at the project root (from `.env.example`):

‚îú‚îÄ‚îÄ android/                 # Native Android project

‚îú‚îÄ‚îÄ scripts/                 # Build and automation scripts```

‚îÇ   ‚îî‚îÄ‚îÄ build.jsTMDB_API_KEY=YOUR_TMDB_KEY

‚îú‚îÄ‚îÄ App.js                   # Root componentSPOTIFY_PROXY_BASE=https://your-proxy.example.com

‚îú‚îÄ‚îÄ package.json```

‚îî‚îÄ‚îÄ README.md

````react-native-config` will expose these as `Config.TMDB_API_KEY` & `Config.SPOTIFY_PROXY_BASE`.



## üöÄ Quick Start## 4) Permissions



### Prerequisites### Android (`android/app/src/main/AndroidManifest.xml`)

```xml

- Node.js >= 18<uses-permission android:name="android.permission.CAMERA"/>

- React Native CLI```

- Xcode (for iOS)

- Android Studio (for Android)### iOS (`ios/YourApp/Info.plist`)

- CocoaPods```xml

<key>NSCameraUsageDescription</key>

### Installation<string>On-device mood detection.</string>

`````

````bash

# Install dependencies## 5) Run it

npm install

```bash

# Install iOS podsnpm run android

cd ios && arch -arm64 pod install && cd ..# or

```npm run ios

````

### Environment Setup

You should see:

Create a `.env` file in the root directory:- Onboarding ‚Üí Capture (simulated detection) ‚Üí Intent ‚Üí Recommendations (movies from TMDb)

````env## 6) Next Up: Real Emotion Detection

SPOTIFY_PROXY_BASE=https://your-spotify-proxy.com/api/spotify- Use **react-native-vision-camera** + a **Frame Processor** to run a tiny classifier (TFLite) and update `useEmotionDetector.js` with real outputs.

TMDB_API_KEY=your_tmdb_api_key- Keep inference **on-device**. Only send mood labels to services.

VISION_API_ENDPOINT=http://your-vision-api-endpoint.com

```## 7) Spotify Music (Optional)

Stand up a tiny proxy (Cloudflare Worker/Node) for client-credentials + `/recommend` hits. App calls `/recommend?target_energy=...` with features from `mapMood.js`.

**Important**: No spaces around `=` sign in `.env` file!

## Notes

## üî® Building & Running- Pure **JavaScript**; no TypeScript.

- Designed for **fast hackathon demo** with a clean upgrade path to real camera inference.

### Development

**Enjoy VibePlay (JS)!** üöÄ

```bash
# Start Metro bundler
npm start

# Run on iOS
npm run ios

# Run on Android
npm run android
````

### Production Builds

```bash
# Build iOS release
npm run ios:release

# Build Android release
npm run android:release
```

### Using Build Script

The project includes a unified build script that uses `src/config/build.config.json`:

```bash
# iOS debug build
node scripts/build.js ios debug

# iOS release build
node scripts/build.js ios release

# Android debug build
node scripts/build.js android debug

# Android release build
node scripts/build.js android release
```

## ‚öôÔ∏è Configuration

### Build Configuration

Edit `src/config/build.config.json` to manage:

- App name and bundle identifiers
- iOS signing certificates and provisioning profiles
- Android keystore configuration
- Build variants and schemes

### App Configuration

Edit `src/config/index.js` for:

- API endpoints
- Feature flags
- Environment-specific settings

## üèóÔ∏è Architecture

### State Management

- **Zustand** for global state (`src/state/store.js`)
- Manages mood, energy, valence, and intent

### Navigation

- **React Navigation** (Native Stack)
- Flow: Onboarding ‚Üí CaptureMood ‚Üí Intent ‚Üí Recommendations ‚Üí Saved

### Emotion Detection

- **Google Cloud Vision API** for face emotion detection
- Images sent securely to backend (not stored permanently)
- Image compression before upload (max 800x800px, 70% quality)
- Maps 6 Vision API fields to 9 app emotions
- Backend URL: AWS Elastic Beanstalk (configurable in `.env`)

**Privacy Note:** Photos are processed via Google Cloud Vision API through your backend server. Images are analyzed for facial features and emotion detection but are not stored. The app receives only the emotion analysis results.

### Recommendations

- **TMDb API** for movie recommendations
- **Spotify API** (via proxy) for music recommendations
- Mood mapping system converts emotions to API parameters

## üé® Theme System

Located in `src/theme/`:

- `colors.js` - Dark neon palette
- `styles.js` - Shared component styles

## üîí Privacy & Security

### How Emotion Detection Works

1. **Capture**: App captures photo using device camera
2. **Compress**: Image resized to 800x800px at 70% quality (~100-300KB)
3. **Send**: Compressed image sent to your backend via HTTPS
4. **Process**: Backend forwards to Google Cloud Vision API
5. **Analyze**: Vision API returns emotion likelihood scores
6. **Map**: App maps 6 API fields to 9 emotions (happy, sad, etc.)
7. **Discard**: Image is not stored - only emotion data returned

### Data Flow

```
Camera ‚Üí App ‚Üí Your Backend ‚Üí Google Vision API ‚Üí Emotion Results
         ‚Üì                                              ‚Üì
    [Compressed]                                   [No Storage]
```

### Security Measures

- ‚úÖ Images compressed before transmission (reduces bandwidth)
- ‚úÖ HTTPS encryption for all API calls (production recommended)
- ‚úÖ No permanent storage of photos
- ‚úÖ Only emotion analysis results retained
- ‚úÖ Backend URL configurable (use your own server)
- ‚ö†Ô∏è Development: HTTP allowed for local testing (disable in production)

### Privacy Considerations

**What's Sent:**

- Compressed photo (temporary, for analysis only)

**What's NOT Sent:**

- User identity
- Location data
- Device information
- Personal metadata

**What You Control:**

- Backend server location
- Vision API credentials
- Data retention policies (on your backend)

**Recommendation for Production:**

- Use HTTPS for all connections
- Implement rate limiting on backend
- Add authentication if needed
- Consider GDPR/privacy compliance for your region

## üßπ Clean Commands

```bash
# Full clean and reinstall
npm run clean

# Clean iOS build
cd ios && rm -rf build Pods Podfile.lock

# Clean Android build
cd android && ./gradlew clean
```

## üì± Platform-Specific Notes

### iOS

- **Minimum iOS**: 13.0
- **App Transport Security**: HTTP allowed for development backend
- **Permissions**: Camera, Photo Library

### Android

- **Minimum SDK**: 21 (Android 5.0)
- **Target SDK**: 34
- **Permissions**: Camera, Internet

## üîß Troubleshooting

### Metro Bundler Issues

```bash
# Reset Metro cache
npm start -- --reset-cache
```

### iOS Build Issues

```bash
# Clean and reinstall pods
cd ios
rm -rf Pods Podfile.lock build
arch -arm64 pod install
cd ..
```

### Android Build Issues

```bash
# Clean Gradle
cd android
./gradlew clean
cd ..
```

## üì¶ Dependencies

### Core

- React Native 0.76.0
- React 18.2.0
- React Navigation 7.x
- Zustand 5.0.8

### UI & Camera

- react-native-vision-camera 4.7.2
- react-native-reanimated 3.16.1
- react-native-safe-area-context 4.8.2
- @bam.tech/react-native-image-resizer 3.0.11

### Utilities

- react-native-fs 2.20.0
- react-native-dotenv 3.4.11

## ü§ù Contributing

1. Follow the existing project structure
2. Keep components in appropriate directories
3. Update `build.config.json` for configuration changes
4. Run linting before committing: `npm run lint`

## üìÑ License

MIT

## üôè Acknowledgments

- Google Cloud Vision API for emotion detection
- TMDb for movie data
- Spotify for music recommendations
